# Forecast Degradation Functions

## Introduction

```{r setup, include=FALSE}
base64stringify <- function(path){
  paste0("data:image/png;base64 ",knitr::image_uri(path))
}
knitr::opts_chunk$set(echo = TRUE, fig.process=base64stringify)
```

Suppose we wanted to forecast the probability of an event occurring sometime in the near future. We can (and should) adjust our forecast as time passes. Every moment the event doesn't occur is another moment in which it no longer can, so probability estimates should go downwards and converge on zero at the moment the forecast window resolves negatively. But how do we decide what the probability should be as a function of the remaining amount of time?

Intuition suggests we might simply draw a straight line descending from your present estimate to zero at resolve time, like so:

```{r}
library(ggplot2)
library(magrittr)

n <- 365
days <- 1:365

linear <- data.frame(
  Day = days,
  Probability = 1-(days/n)
)

ggplot(linear, aes(Day, Probability)) + geom_line()
```

How good a strategy is this? To assess, let's employ one of the standard scoring metrics of forecasting: [the Brier score](https://en.wikipedia.org/wiki/Brier_score). Briefly, a Brier score is a "proper" scoring metric["Proper" means that it gives the highest expected reward for reporting the true probability distribution.](sidenote), typically in the range of 0 to 1, where 0 is perfect prediction and 1 is *exactly* incorrect prediction. There's an important thing to note about such scores--if you can generate a prediction which scores close to 1, then you can also generate a prediction close to 0 by simply predicting the logical opposite. Thus there can be an odd sort of triumph in getting a very bad Brier score--simply predict the opposite to transform it into a very good Brier score. By this reasoning, the score you really want to avoid is the one which tells you that you aren't predicting the system any better (or worse) than a coin-flip. That score is the midrange, 0.5. So, back to the question at hand, how good is our linear degradation function?

```{r}
library(DescTools)
BrierScore(linear$Probability, 0)
```
[Note that the only way to assess the degradation function over its entire history is to score it for an event that never occurred (hence the 0). If it had occurred, we would have to truncate the vector of predictions at the time of the occurrence. We'll come back to this!](marginnote)

Pretty terrible! Fortunately, we may be able to do a bit better. Suppose that we believe, on the last day of the challenge, that the probability of a positive resolution is 1%. Not based on any super strong evidence, mind you--you just don't think there's a 0% outcome probability on any given day.[For convenience, we'll assume that the predictions are being generated over a time series of discrete days, though any discrete unit of time may be applicable.](sidenote) So, given this, what should you have predicted the day before?

The outcome probability over the remaining prediction window is the conjunctive probability that it doesn't occur in any of the window's constituent days, so $1-(1-0.01)^2$. We can generalize this in a few ways. Suppose we want to assess that probability over $n$ days--that's given by replacing the exponent ($1-(1-0.01)^n$). And Suppose we want to assess the probability with a variable probability, instead of a constant 0.01. To do this, replace the probability with a variable, $p$, as in $1-(1-p)^n$. So, given this arrangement, what's the probability at the beginning of the year?

```{r}
exponential <- data.frame(
  Day = days,
  Probability = (1-0.01)^(days)
)

ggplot(exponential, aes(Day, Probability)) + geom_line()
```

Some interesting things to note here:
1. An event with a daily probability of 1% occurs over the course of a year with a probability of 98%.
2. But it isn't linear. Notably, this causes .5 

```{r}
BrierScore(exponential$y, 0)
```

Which is fine, but we need to be able to go the opposite direction. If I did my algebra correctly, the transformed equation looks something like this:

$$p\_s=1-exp(ln(1-p\_w)/n)$$
where $p\_s$ is the independent probability of the event on each discrete time step, $p\_w$ is the annual probability, $n$ is the number of discrete



Given an initial probability over the course of some finite time window, what's the continuous function we need in order to provide an honest degradation of our prediction?
